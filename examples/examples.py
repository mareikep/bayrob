import argparse
import ast
import datetime
import os
import re
import sys
from multiprocessing import Manager
from pathlib import Path

import dnutils
import numpy as np
import pandas as pd
import plotly.graph_objects as go
from jpt.base.intervals import ContinuousSet
from sklearn.model_selection import train_test_split

from bayrob.logs.logs import init_loggers
from bayrob.utils import locs
from bayrob.utils.constants import bayroblogger, FILESTRFMT
from bayrob.utils.plotlib import plot_heatmap, fig_to_file, defaultconfig
from bayrob.utils.utils import recent_example
from jpt import JPT, infer_from_dataframe
from jpt.distributions import Distribution, Numeric
from jpt.learning.c45 import JPTPartition, _locals
from jpt.variables import VariableMap

try:
    import perception
    import robotaction
    import gridagent
except ModuleNotFoundError:
    sys.path.append(os.path.join('..', 'examples'))


logger = dnutils.getlogger(bayroblogger, level=dnutils.DEBUG)

manager = Manager()
distributions = manager.dict()


def do_prune(
        jpt: JPT,
        partition: JPTPartition,
        indices: np.ndarray
):
    data = _locals.data
    node_idx = partition.node_idx

    distributions[node_idx] = manager.dict()

    for i, v in enumerate(jpt.targets):
        dist = v.distribution()._fit(
            data=data,
            rows=indices[partition.start:partition.end],
            col=jpt.variables.index(v)
        )
        distributions[node_idx][v] = dist

    if partition.parent_idx is None:  # FIXME
        return False

    similarities = VariableMap(variables=jpt.targets)
    for v in jpt.targets:
        child_dist: Distribution = distributions[node_idx][v]
        parent_dist: Distribution = distributions[partition.parent_idx][v]

        if isinstance(child_dist, Numeric):
            parent_dist = parent_dist.crop(child_dist.pdf.domain())
        else:
            parent_dist = parent_dist.crop({
                v for v in parent_dist.labels.values() if child_dist.p(v)
            })

        similarities[v] = v.domain.jaccard_similarity(child_dist, parent_dist)

    total_similarity = 1 * (1 - (partition.end - partition.start) / data.shape[0]) + (partition.end - partition.start) / data.shape[0] * np.min(
        list(similarities.values()))

    if total_similarity > .99:
        return True
    else:
        return False


def learn_jpt(
        fp,
        args
):
    name = args.example

    logger.debug(f'learning constrained {name} JPT...')

    # learn discriminative JPT from data generated by test_data_curation for PERCEPTION
    df = pd.read_parquet(
        os.path.join(fp, 'data', f'000-{name}.parquet'),
    )

    logger.debug('Got dataframe of shape:', df.shape)

    constraints = args.constraints if 'constraints' in args else None
    if constraints is not None:
        c = [(var, op, v) for var, val in constraints.items() for v, op in ([(val.lower, ">="), (val.upper, "<=")] if isinstance(val, ContinuousSet) else [(val, "==")])]
        s = ' & '.join([f'({var} {op} {num})' for var, op, num in c])
        logger.debug('Extracting dataset using query: ', s)
        df = df.query(s)
        logger.debug('Returned subset of shape:', df.shape)

    variables = args.variables if 'variables' in args else None
    if variables is not None:
        logger.debug(f'Restricting dataset to columns: {variables}')
        df = df[variables]

    variables = infer_from_dataframe(
        df,
        scale_numeric_types=False,
        precision=.025
    )

    # targets can be specified either by
    #   a) index or
    #   b) comma-separated string of variable names
    #   c) comma-separated string of variable names of features
    tgtidx = args.tgtidx if 'tgtidx' in args else None
    ftidx = args.ftidx if 'ftidx' in args else None

    targets = args.targets if 'targets' in args else None
    features = args.features if 'features' in args else None

    tgts = None
    fts = None
    if tgtidx is not None:
        tgts = variables[int(tgtidx):]
    if ftidx is not None:
        fts = variables[:ftidx]

    if targets is not None:
        tgts = [v for v in variables if v.name in targets]
    if features is not None:
        fts = [v for v in variables if v.name in features]

    logger.debug(f"passing targets {tgts} to JPT")
    logger.debug(f"passing features {fts} to JPT")
    print(args)
    jpt_ = JPT(
        variables=variables,
        targets=tgts,
        features=fts,
        min_impurity_improvement=args.min_impurity_improvement,
        min_samples_leaf=args.min_samples_leaf,
        max_depth=args.max_depth if "max_depth" in args else None
    )

    jpt_.learn(
        df,
        close_convex_gaps=False,
        prune_or_split=do_prune if args.prune else None,
        verbose=True
    )

    if "postprocess" in args:
        logger.debug(f"Post-processing leaves...")
        jpt_.postprocess_leaves()

    logger.debug(f'...done! saving to file {os.path.join(fp, f"000-{name}.tree")}')
    jpt_.save(os.path.join(fp, f'000-{name}.tree'))
    logger.debug('...done.')


def crossval(fp, args):
    ex = args.example

    if ex == 'move':
        settings = {
            "prune-generative": {
                'min_samples_leaf': 0.001,
                'targets': None,
                'prune_or_split': True
            },
            "prune-discriminative": {
                'min_samples_leaf': 0.001,
                'targets': 4,
                'prune_or_split': True
            },
            "noprune-generative": {
                'min_samples_leaf': 0.001,
                'targets': None,
                'prune_or_split': False
            },
            "noprune-discriminative": {
                'min_samples_leaf': 0.001,
                'targets': 4,
                'prune_or_split': False
            },
        }
    elif ex == 'perception':
        settings = {
            "prune-msl-0005": {
                'min_samples_leaf': 0.05,
                'targets': None,
                'prune_or_split': True
            },
            "prune-msl-01": {
                'min_samples_leaf': 0.1,
                'targets': None,
                'prune_or_split': True
            },
            "noprune-msl-0005": {
                'min_samples_leaf': 0.005,
                'targets': None,
                'prune_or_split': False
            },
            "noprune-msl-01": {
                'min_samples_leaf': 0.1,
                'targets': None,
                'prune_or_split': False
            },
        }
    elif ex == 'pr2':
        settings = {}
    elif ex == 'turn':
        settings = {}
    else:
        logger.error('Invalid example', ex)
        return

    if not os.path.exists(os.path.join(fp, 'crossval')):
        os.mkdir(os.path.join(fp, 'crossval'))

    likelihoods_pervar = {}
    likelihoods_cumulated = {}

    # loading test data file
    logger.debug(f"Loading {os.path.join(fp, 'data', f'000-{args.example}.parquet')}...")
    df_ = pd.read_parquet(os.path.join(fp, 'data', f'000-{args.example}.parquet'))

    # shuffle data and divide into training and test sets
    df_train, df_test = train_test_split(df_, test_size=0.1, shuffle=True)

    # infer variables
    variables = infer_from_dataframe(
        df_,
        scale_numeric_types=False,
        precision=.025
    )

    for sname, setting in settings.items():
        logger.debug(f'Learning tree for setting {sname}...', setting)

        tgts = None
        if setting.get('targets', None) is not None:
            tgts = variables[int(setting.get('targets', None)):]

        jpt_ = JPT(
            variables=variables,
            targets=tgts,
            min_impurity_improvement=setting.get('min_impurity_improvement', None),
            min_samples_leaf=setting.get('min_samples_leaf', None),
            max_depth=setting.get('max_depth', None)
        )

        jpt_.learn(
            df_,
            close_convex_gaps=False,
            prune_or_split=do_prune if setting['prune_or_split'] else None,
            verbose=True
        )

        # for v in jpt_.variables:
        #     jpt_.priors[v].plot(view=True)

        logger.debug(f'...done! saving to file {os.path.join(fp, "crossval", f"{sname}.tree")}')
        jpt_.save(os.path.join(fp, "crossval", f"{sname}.tree"))

        # for each datapoint in test dataset, calculate and save likelihood
        logger.debug(f"Calculating likelihoods for setting {sname}...")
        probspervar = jpt_.likelihood(df_test, single_likelihoods=True)
        probs = jpt_.likelihood(df_test, single_likelihoods=False)
        likelihoods_pervar[sname] = np.mean(probspervar, axis=0)
        likelihoods_cumulated[sname] = np.mean(probs)

        distributions.clear()

    # plot heatmap comparing likelihoods of multiple trees per variable
    data_pervar = list(likelihoods_pervar.values())
    data = pd.DataFrame(
        data=[[np.array(list(likelihoods_pervar.keys())), np.array([v.name for v in variables]),
               np.array([np.around(d, decimals=2) for d in data_pervar]).T, np.array(data_pervar).T, np.array(data_pervar).T]],
        columns=['tree', 'variable', 'text', 'z', 'lbl']
    )
    # draw matrix tree x variable = likelihood(tree, datapoint)
    plot_heatmap(
        data=data,
        xvar='tree',
        yvar='variable',
        text='text',
        save=os.path.join(fp, 'crossval', f'likelihoods_per_variable.html')
    )

    # plot heatmap comparing overall likelihoods of multiple trees
    fig_s = go.Figure()
    fig_s.add_trace(
        go.Bar(
            x=list(likelihoods_cumulated.keys()),
            y=list(likelihoods_cumulated.values()),
            text=list(likelihoods_cumulated.values()),
            orientation='v',
            marker=dict(
                color='rgb(15,21,110,.6)',
                line=dict(color='rgb(15,21,110)', width=3)
            )
        )
    )
    fig_s.update_layout(
        xaxis_title='setting',
        yaxis_title='likelihood',
        showlegend=False,
        width=1000,
        height=1000,
        yaxis={}
    )
    fig_to_file(fig_s, os.path.join(fp, 'crossval', f'likelihoods_cumulated.html'))
    fig_s.show(config=defaultconfig("likelihoods_cumulated.html"))

def kfold(
        fp,
        args
):
    name = args.example

    logger.debug(f'learning constrained {name} JPT...')

    # learn discriminative JPT from data generated by test_data_curation for PERCEPTION
    df_ = pd.read_parquet(os.path.join(fp, 'data', f'000-{name}.parquet'))

    logger.debug('Got dataframe of shape:', df_.shape)

    constraints = args.constraints if 'constraints' in args else None
    if constraints is not None:
        c = [(var, op, v) for var, val in constraints.items() for v, op in ([(val.lower, ">="), (val.upper, "<=")] if isinstance(val, ContinuousSet) else [(val, "==")])]
        s = ' & '.join([f'({var} {op} {num})' for var, op, num in c])
        logger.debug('Extracting dataset using query: ', s)
        df_ = df_.query(s)
        logger.debug('Returned subset of shape:', df_.shape)

    # shuffle dataframe, then split it into args.crossfold sets
    df_ = df_.sample(frac=1)
    df_folds = np.array_split(df_, args.crossfold)
    if not os.path.exists(os.path.join(fp, 'folds')):
        os.mkdir(os.path.join(fp, 'folds'))
    for i, d in enumerate(df_folds):
        d.to_parquet(os.path.join(fp, 'folds', f'000-{args.example}-fold-{i}.parquet'), index=False)

    for i, df__ in enumerate(df_folds):

        # if crossfolds mode, generate training set by concatenating all but one subset
        if len(df_folds) > 1:
            df = pd.concat([d for j, d in enumerate(df_folds) if i != j])
            name = f"{args.example}-without-{i}"
            fp_ = os.path.join(fp, 'folds')
        else:
            df = df__
            fp_ = fp

        variables = args.variables if 'variables' in args else None
        if variables is not None:
            logger.debug(f'Restricting dataset to columns: {variables}')
            df = df[variables]

        variables = infer_from_dataframe(
            df,
            scale_numeric_types=False,
            precision=.025
        )

        # targets can be specified either by
        #   a) index or
        #   b) comma-separated string of variable names
        #   c) comma-separated string of variable names of features
        tgtidx = args.tgtidx if 'tgtidx' in args else None
        targets = args.targets if 'targets' in args else None
        features = args.features if 'features' in args else None
        tgts = None
        if tgtidx is not None:
            tgts = variables[int(tgtidx):]
        if targets is not None:
            tgts = [v for v in variables if v.name in targets]
        if features is not None:
            tgts = [v for v in variables if v.name not in features]

        logger.debug(f"passing targets {tgts} to JPT")
        jpt_ = JPT(
            variables=variables,
            targets=tgts,
            min_impurity_improvement=args.min_impurity_improvement,
            min_samples_leaf=args.min_samples_leaf,
            max_depth=args.max_depth if "max_depth" in args else None
        )

        jpt_.learn(
            df,
            close_convex_gaps=False,
            prune_or_split=do_prune if args.prune else None,
            verbose=True
        )

        if "postprocess" in args:
            logger.debug(f"Post-processing leaves...")
            jpt_.postprocess_leaves()

        logger.debug(f'...done! saving to file {os.path.join(fp_, f"000-{name}.tree")}')
        jpt_.save(os.path.join(fp_, f'000-{name}.tree'))
        logger.debug('...done.')


def crossval_plot(fp, args):
    d = {}
    for treefile in Path(os.path.join(fp, 'folds')).rglob('*.tree'):
        # load tree file
        tn = treefile.name
        print(f"Loaded tree {tn}")
        t = JPT.load(str(treefile))

        # determine respective test dataset for this tree and load it
        match = re.search(r"(\d+)\.tree", tn)
        if match:
            df_id = match.groups()[0]
        else:
            continue

        print(f"Loading fold {df_id}")
        df_ = pd.read_parquet(os.path.join(fp, 'folds', f'000-{args.example}-fold-{df_id}.parquet'))

        # for each datapoint in test dataset, calculate and save likelihood
        print(f"Calculating likelihoods")
        # probspervar = t.likelihood(df_, single_likelihoods=True)
        probs = t.likelihood(df_, single_likelihoods=False)

        # d[tn] = np.mean(probspervar, axis=0)

    data = list(d.values())
    data = pd.DataFrame(
        data=[[np.array(list(d.keys())), np.array([v.name for v in t.variables]), np.array([np.around(d, decimals=2) for d in data]).T, np.array(data).T, np.array(data).T]],
        columns=['tree', 'variable', 'text', 'z', 'lbl']
    )
    # draw matrix tree x datapoint = likelihood(tree, datapoint)
    plot_heatmap(
        data=data,
        xvar='tree',
        yvar='variable',
        text='text',
        save=os.path.join(fp, 'folds', f'000-{args.example}-kfold-hm.html')
    )


def plot_jpt(fp, args):
    name = args.example

    logger.debug(f'plotting {name} tree without distributions...')
    jpt_ = JPT.load(os.path.join(fp, f'000-{name}.tree'))
    jpt_.plot(
        title=name,
        filename=f'000-{name}-nodist',
        directory=os.path.join(fp, 'plots'),
        leaffill='#CCDAFF',
        nodefill='#768ABE',
        alphabet=True,
        view=args.showplots
    )

    logger.debug(f'plotting {name} tree...')
    jpt_.plot(
        title=name,
        plotvars=list(jpt_.variables),
        filename=f'000-{name}',
        directory=os.path.join(fp, 'plots'),
        leaffill='#CCDAFF',
        nodefill='#768ABE',
        alphabet=True,
        view=args.showplots
    )


def main(DT, args):

    fp = os.path.join(locs.examples, args.example, DT)

    if not os.path.exists(fp):
        os.mkdir(fp)
        os.mkdir(os.path.join(fp, 'plots'))
        os.mkdir(os.path.join(fp, 'data'))

    if args.example == 'turn':
        from turn import turn as mod
    elif args.example == 'move':
        from move import move as mod
    elif args.example == 'move_exp':
        from move_exp import move as mod
    elif args.example == 'perception':
        from perception import perception as mod
    elif args.example == 'pr2':
        from pr2 import pr2 as mod
    else:
        from perception import perception as mod
        args.example = 'perception'

    mod.init(fp, args)

    if not args.recent:
        mod.generate_data(fp, args)

    if args.learn:
        if args.modulelearn:
            mod.learn_jpt(fp, args)
        else:
            learn_jpt(fp, args)

    if args.crossval:
        crossval(fp, args)

    if args.kfold > 0:
        kfold(fp, args)
        crossval_plot(fp, args)

    if args.plot:
        plot_jpt(fp, args)

    if args.data:
        mod.plot_data(fp, args)

    mod.teardown(fp, args)


if __name__ == '__main__':

    # The arguments are not limited to the list below. For any example-specific arguments use the -a (--args), e.g.
    # python example -o -l -p -a prune 0.77

    parser = argparse.ArgumentParser(description='BayRoBWeb.')
    parser.add_argument("-v", "--verbose", dest="verbose", default='debug', type=str, action="store", help="Set verbosity level {debug,info,warning,error,critical}. Default is info.")
    parser.add_argument('--recent', action='store_true', help='use most recent folder created', required=False)
    parser.add_argument('--learn', action='store_true', help='learn model', required=False)
    parser.add_argument('--modulelearn', action='store_true', help='use learning function of module. if not given, use default learning function', required=False)
    parser.add_argument('--plot', action='store_true', help='plot model', required=False)
    parser.add_argument('--showplots', action='store_true', help='show plots', required=False)
    parser.add_argument('--targets', nargs='+')
    parser.add_argument('--features', nargs='+')
    parser.add_argument('--data', action='store_true', help='trigger generating data/world plots', required=False)
    parser.add_argument('--obstacles', action='store_true', help='obstacles', required=False)
    parser.add_argument('--prune', action='store_true', help='pass prune or split callable to model learning function', required=False)
    parser.add_argument('--kfold', type=int, default=-1, help='learn multiple models', required=False)
    parser.add_argument('--crossval', action='store_true', help='run crossval with different settings', required=False)
    parser.add_argument('-a', '--args', action='append', nargs=2, metavar=('arg', 'value'), help='other, example-specific argument of type (arg, value)')
    parser.add_argument('-e', '--example', type=str, default='perception', help='name of the data set', required=False)
    parser.add_argument('--min-samples-leaf', type=float, default=1, help='min_samples_leaf parameter', required=False)
    parser.add_argument('--min-impurity-improvement', type=float, default=None, help='impurity_improvement parameter', required=False)
    args = parser.parse_args()

    init_loggers(level=args.verbose)

    d = vars(args)
    if args.args is not None:
        for k, v in args.args:
            try:
                d[k] = ast.literal_eval(v)
            except:
                d[k] = v

    logger.info(f"Running example {args.example} with arguments: \n{', '.join(f'{k}={v}' for k, v in d.items() if k != 'args')})")

    # use most recently created dataset or create from scratch
    if args.recent:
        DT = recent_example(os.path.join(locs.examples, args.example))
        logger.debug(f'Using recent directory {DT}')
    else:
        DT = f'{datetime.datetime.now().strftime(FILESTRFMT)}'
        logger.debug(f'Creating new directory {DT}')

    main(DT, args)
